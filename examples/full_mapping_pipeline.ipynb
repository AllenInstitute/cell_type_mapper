{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48955202-8a6c-4ca1-98bd-29ee3f5e902d",
   "metadata": {},
   "source": [
    "In this notebook, we will demonstrate how to run the full `cell_type_mapper` pipeline starting from h5ad files containing reference and unabeled data: creating the `precomputed_stats` and `query_marker` files needed to run the mapping, and finally running the `cell_type_mapper` on the unlabeled data.\n",
    "\n",
    "We will be creating all of our data in this notebook, so it is just a \"cartoon.\" The purpose of this cartoon is not to model the statistical properties of actual cell-by-gene data, but to demonstrate how to move data through the `cell_type_mapper` pipeline and how to interpret the results that are produced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578356db-253a-4316-bf4c-6013db2689a4",
   "metadata": {},
   "source": [
    "# 1 -- Create cartoon reference data with a taxonomy\n",
    "\n",
    "First, let's create a cartoon taxonomy and example labeled and unlabeled data. The labeled data will be formatted such that it can be run through the `precomputed_stats_scrattch` command line tool (i.e. the cell-by-gene data and the taxonomy will all be stored in one h5ad file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0b52260-33c5-462c-b70a-d5048cc2fa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata\n",
    "import h5py\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a33aa4b-d478-4141-a35a-d9041b753296",
   "metadata": {},
   "source": [
    "First, let's create a temporary directory where we can store the inputs and outputs produced by this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e9cee84-3a63-4638-82f2-d660a64c7798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temporary directory is pipeline_example_data\n"
     ]
    }
   ],
   "source": [
    "tmp_dir = pathlib.Path('pipeline_example_data')\n",
    "if not tmp_dir.exists():\n",
    "    tmp_dir.mkdir()\n",
    "\n",
    "print(f\"temporary directory is {tmp_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d29395-4a97-4b3e-8ff3-b16f16791895",
   "metadata": {},
   "source": [
    "In the cell below, we define a taxonomy with three classes, which are broken up into a total of five subclasses, which are broken up into a total of eight clusters. The inheritance structure of the taxonomy is encoded in the names of the taxon, so that `cluster_ABC` is a descendent of `subclass_AB` which is a descendant of `class_A` (so, `cluster_101`is a descendant of subclass `subclass_10` which is a descendant of `class_1`). We will create a characteristic gene profile across a panel of 90 genes for each of our classes, subclasses, and clusters. These characteristic profiles are not meant to be realistic. They are engineered so that there genes that are good at discriminating between all pairs of taxons at all levels in our taxonomy.\n",
    "\n",
    "**You should just run this cell without bothering to really understand what it is doing. It only exists to create the reference data for our example.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b58919a8-d9e7-4945-8bbe-cce8c5020374",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(22112)\n",
    "\n",
    "n_genes = 90\n",
    "\n",
    "characteristic_profiles = dict()\n",
    "\n",
    "taxon_list = [\n",
    "    'class_0',\n",
    "    'class_1',\n",
    "    'class_2',\n",
    "    'subclass_00',\n",
    "    'subclass_01',\n",
    "    'subclass_10',\n",
    "    'subclass_11',\n",
    "    'subclass_20',\n",
    "    'cluster_000',\n",
    "    'cluster_001',\n",
    "    'cluster_010',\n",
    "    'cluster_011',\n",
    "    'cluster_100',\n",
    "    'cluster_101',\n",
    "    'cluster_110',\n",
    "    'cluster_200'\n",
    "]\n",
    "\n",
    "cluster_names = [t for t in taxon_list if t.startswith('cluster')]\n",
    "\n",
    "for taxon in taxon_list:\n",
    "    characteristic_profiles[taxon] = np.zeros(n_genes, dtype=float)\n",
    "\n",
    "# create characteristic profiles for classes\n",
    "scratch = np.zeros(n_genes, dtype=float)\n",
    "scratch[:20] = np.linspace(0.0, 200.0, 20)\n",
    "characteristic_profiles['class_0'] += scratch\n",
    "characteristic_profiles['class_1'] += scratch\n",
    "\n",
    "scratch = np.zeros(n_genes, dtype=float)\n",
    "scratch[20:30] = np.linspace(0.0, 175.0, 10)[-1::-1]\n",
    "characteristic_profiles['class_0'] += scratch\n",
    "\n",
    "scratch = np.zeros(n_genes, dtype=float)\n",
    "scratch[10:30] = 2.0*(np.arange(10, 30, dtype=float)-20)**2\n",
    "characteristic_profiles['class_2'] += scratch\n",
    "\n",
    "# create characteristic profiles for subclasses\n",
    "\n",
    "vec0 = np.zeros(n_genes, dtype=float)\n",
    "vec0[30:60] = np.linspace(0.0, 200.0, 30)\n",
    "\n",
    "vec1 = np.zeros(n_genes, dtype=float)\n",
    "vec1[30:60] = np.linspace(0, 200.0, 30)[-1::-1]\n",
    "\n",
    "for taxon in taxon_list:\n",
    "    if 'subclass' not in taxon:\n",
    "        continue\n",
    "    tag = taxon.split('_')[-1]\n",
    "    class_tag = tag[0]\n",
    "    characteristic_profiles[taxon] += characteristic_profiles[f'class_{class_tag}']\n",
    "    subclass_tag = tag[-1]\n",
    "    if subclass_tag == '0':\n",
    "        characteristic_profiles[taxon] += vec0\n",
    "    else:\n",
    "        assert subclass_tag == '1'\n",
    "        characteristic_profiles[taxon] += vec1\n",
    "\n",
    "    params =rng.choice(np.arange(1,30, dtype=int), 2)\n",
    "    wave = 0.5*(1.0+np.sin(2.0*np.pi*(np.arange(30)+params[1])/params[0]))\n",
    "    characteristic_profiles[taxon][30:60] *= wave\n",
    "\n",
    "# create characteristic profiles for clusters\n",
    "\n",
    "for taxon in taxon_list:\n",
    "    if 'cluster' not in taxon:\n",
    "        continue\n",
    "\n",
    "    params = 1.0+rng.random(2)*6.0\n",
    "    wave = 100.0*(1.0+np.sin(2.0*np.pi*np.arange(15)/params[0]+params[1]))\n",
    "\n",
    "    tag = taxon.split('_')[-1]\n",
    "    subclass_tag = tag[:2]\n",
    "    characteristic_profiles[taxon] += characteristic_profiles[f'subclass_{subclass_tag}']\n",
    "    cluster_tag = tag[-1]\n",
    "    if cluster_tag == '0':\n",
    "        characteristic_profiles[taxon][60:75] += wave\n",
    "    else:\n",
    "        assert cluster_tag == '1'\n",
    "        characteristic_profiles[taxon][75:90] += wave\n",
    "\n",
    "    params =rng.choice(np.arange(1,10, dtype=int), 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc11c15-5150-4e29-8e96-1d76065b0586",
   "metadata": {},
   "source": [
    "The cell below defines a helper function for generating noisy gene expression profiles drawn from our taxonomy.\n",
    "\n",
    "**Again, you do not need to understand what this does in detail if you do not want to. It is not designed to be a realistic simulation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87825e2a-229a-4774-88d8-13f666b3f0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_noisy_cell(taxon_to_wgt, rng, n_dropouts=10):\n",
    "    \"\"\"\n",
    "    A helper function to create a cell which is a member of one of our cartoon taxons, but with a noisy gene expression profile.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    taxon_to_wgt:\n",
    "        A dict mapping cell type taxon to the numeric weight multiplied by the taxon's characteristic gene expression profile\n",
    "        when assembling our simulated cell's gene expression profile (i.e. the simulated cell will be a linear combination\n",
    "        of characteristic gene expression profiles).\n",
    "    rng:\n",
    "        a numpy random number generator\n",
    "    n_dropouts:\n",
    "        select this many genes to randomly drop out of the cell\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A numpy array of raw gene expression (ints) for the simulated cell.\n",
    "    \"\"\"\n",
    "\n",
    "    # assemble the linear combination of characteristic gene expression profiles\n",
    "    norm = 0.0\n",
    "    this_cell = np.zeros(n_genes, dtype=float)\n",
    "    for taxon in taxon_to_wgt:\n",
    "        this_cell += taxon_to_wgt[taxon]*characteristic_profiles[taxon]\n",
    "        norm += taxon_to_wgt[taxon]\n",
    "    this_cell = this_cell/norm\n",
    "\n",
    "    # for each gene, draw from a Poisson distribution centered on the value resulting\n",
    "    # from the linear combination above\n",
    "    nonzero = np.where(this_cell>0.0)\n",
    "    this_cell[nonzero] = rng.poisson(\n",
    "        this_cell[nonzero])\n",
    "\n",
    "    # set dropout genes to 0.0\n",
    "    if n_dropouts > 0:\n",
    "        sorted_dex = np.argsort(this_cell)\n",
    "        valid_for_dropout = np.ones(len(this_cell), dtype=bool)\n",
    "        valid_for_dropout[this_cell<0.5] = False\n",
    "\n",
    "        if valid_for_dropout.sum() > n_dropouts:\n",
    "            dropout_genes = rng.choice(np.where(valid_for_dropout)[0], n_dropouts, replace=False)\n",
    "            this_cell[dropout_genes] = 0.0\n",
    "\n",
    "    # clip negative values and convert to integers\n",
    "    this_cell = np.clip(this_cell, a_min=0.0, a_max=None)\n",
    "    this_cell = np.round(this_cell).astype(int)\n",
    "    \n",
    "    return this_cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb97cff-b19d-4eb3-b184-8104650df547",
   "metadata": {},
   "source": [
    "The cell below creates an h5ad file containing the reference data we will use for our mapping.\n",
    "\n",
    "**Just run this cell. We will look at its output below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9a28cbe-dfd3-4a8a-9289-36a5b6eb01f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_data is at pipeline_example_data/training_data.h5ad\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.default_rng(6611222)\n",
    "\n",
    "n_labeled_cells = 2000\n",
    "\n",
    "var = pd.DataFrame(\n",
    "    [{'gene_id': f'g{ii}'} for ii in range(n_genes)]\n",
    ").set_index('gene_id')\n",
    "\n",
    "obs_data = []\n",
    "cell_by_gene = np.zeros((n_labeled_cells, n_genes))\n",
    "for i_cell in range(n_labeled_cells):\n",
    "    #chosen_cluster = rng.choice(cluster_names)\n",
    "\n",
    "    cluster_name_list = rng.choice(cluster_names, 2, replace=True)\n",
    "    chosen_cluster = cluster_name_list[0]\n",
    "    other_cluster = cluster_name_list[1]\n",
    "\n",
    "    if other_cluster == chosen_cluster:\n",
    "        taxon_to_wgt = {chosen_cluster: 1.0}\n",
    "    else:\n",
    "        if chosen_cluster[:-1] == other_cluster[:-1]:\n",
    "            a0 = rng.normal(0.8, 0.05)\n",
    "        elif chosen_cluster[:-2] == other_cluster[:-2]:\n",
    "            a0 = rng.normal(0.9, 0.05)\n",
    "        else:\n",
    "            a0 = rng.normal(0.95, 0.02)\n",
    "\n",
    "        if a0 > 1.0:\n",
    "            a0 = 1.0\n",
    "        elif a0 < 0.0:\n",
    "            a0 = 0.0\n",
    "        a1 = 1.0 - a0\n",
    "\n",
    "        if a1 > a0:\n",
    "            _t = other_cluster\n",
    "            other_cluster = chosen_cluster\n",
    "            chosen_cluster = _t\n",
    "            _t = a1\n",
    "            a1 = a0\n",
    "            a1 = _t\n",
    "\n",
    "        taxon_to_wgt = {\n",
    "             chosen_cluster: a0,\n",
    "             other_cluster: a1\n",
    "         }\n",
    "\n",
    "    this_cell = create_noisy_cell(\n",
    "        taxon_to_wgt=taxon_to_wgt,\n",
    "        rng=rng\n",
    "    )\n",
    "    \n",
    "    assert this_cell.sum() > 0\n",
    "    cell_by_gene[i_cell, :] = this_cell\n",
    "    tag = chosen_cluster.split('_')[-1]\n",
    "    obs_entry = {\n",
    "        'cell_id': f'cell_{i_cell}',\n",
    "        'cluster': chosen_cluster,\n",
    "        'subclass': f'subclass_{tag[:2]}',\n",
    "        'class': f'class_{tag[0]}'\n",
    "    }\n",
    "    obs_data.append(obs_entry)\n",
    "\n",
    "obs = pd.DataFrame(obs_data).set_index('cell_id')\n",
    "a_data = anndata.AnnData(\n",
    "            X=cell_by_gene,\n",
    "            obs=obs,\n",
    "            var=var\n",
    ")\n",
    "\n",
    "\n",
    "training_data_path = tmp_dir / 'training_data.h5ad'\n",
    "if training_data_path.exists():\n",
    "    training_data_path.unlink()\n",
    "a_data.write_h5ad(training_data_path)\n",
    "print(f\"training_data is at {training_data_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4207d48f-ef20-41cf-a0aa-09744ae5b13e",
   "metadata": {},
   "source": [
    "We just created an h5ad file at `pipeline_example_data/training_data.h5ad`. This h5ad file contains everything we need to select marker genes with the `cell_type_mapper` code base. Let's examine the contents of that h5ad file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b39d98e5-58c0-4c10-a745-3944324a8c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 90)\n"
     ]
    }
   ],
   "source": [
    "src = anndata.read_h5ad('pipeline_example_data/training_data.h5ad', backed='r')\n",
    "print(src.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9324b3-f1cf-4cec-a293-5e40944ec240",
   "metadata": {},
   "source": [
    "The h5ad file is `n_cells` by `n_genes` in size. The `var` dataframe is just an index with the identifiers of the measured genes. Note that, when we finally do the cell type mapping, the code will directly compare these gene identifiers with the index of the `var` dataframe in the unlabeled data. If, for instance, the reference data identifies genes with ENSEMBL IDs and the unlabeled data identifies genes with NCBI IDs, the mapping code will determine that the two datasets have non-overlapping sets of genes, and the mapping will fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70fb8902-96c3-4c41-acf5-043ffa612da3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gene_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>g0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g85</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g86</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g87</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g88</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g89</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 0 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [g0, g1, g2, g3, g4, g5, g6, g7, g8, g9, g10, g11, g12, g13, g14, g15, g16, g17, g18, g19, g20, g21, g22, g23, g24, g25, g26, g27, g28, g29, g30, g31, g32, g33, g34, g35, g36, g37, g38, g39, g40, g41, g42, g43, g44, g45, g46, g47, g48, g49, g50, g51, g52, g53, g54, g55, g56, g57, g58, g59, g60, g61, g62, g63, g64, g65, g66, g67, g68, g69, g70, g71, g72, g73, g74, g75, g76, g77, g78, g79, g80, g81, g82, g83, g84, g85, g86, g87, g88, g89]\n",
       "\n",
       "[90 rows x 0 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src.var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "962688b8-900b-48bf-8d06-8e204b045e49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>subclass</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cell_0</th>\n",
       "      <td>cluster_011</td>\n",
       "      <td>subclass_01</td>\n",
       "      <td>class_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_1</th>\n",
       "      <td>cluster_001</td>\n",
       "      <td>subclass_00</td>\n",
       "      <td>class_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_2</th>\n",
       "      <td>cluster_100</td>\n",
       "      <td>subclass_10</td>\n",
       "      <td>class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_3</th>\n",
       "      <td>cluster_110</td>\n",
       "      <td>subclass_11</td>\n",
       "      <td>class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_4</th>\n",
       "      <td>cluster_200</td>\n",
       "      <td>subclass_20</td>\n",
       "      <td>class_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_1995</th>\n",
       "      <td>cluster_101</td>\n",
       "      <td>subclass_10</td>\n",
       "      <td>class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_1996</th>\n",
       "      <td>cluster_101</td>\n",
       "      <td>subclass_10</td>\n",
       "      <td>class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_1997</th>\n",
       "      <td>cluster_000</td>\n",
       "      <td>subclass_00</td>\n",
       "      <td>class_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_1998</th>\n",
       "      <td>cluster_010</td>\n",
       "      <td>subclass_01</td>\n",
       "      <td>class_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_1999</th>\n",
       "      <td>cluster_000</td>\n",
       "      <td>subclass_00</td>\n",
       "      <td>class_0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               cluster     subclass    class\n",
       "cell_id                                     \n",
       "cell_0     cluster_011  subclass_01  class_0\n",
       "cell_1     cluster_001  subclass_00  class_0\n",
       "cell_2     cluster_100  subclass_10  class_1\n",
       "cell_3     cluster_110  subclass_11  class_1\n",
       "cell_4     cluster_200  subclass_20  class_2\n",
       "...                ...          ...      ...\n",
       "cell_1995  cluster_101  subclass_10  class_1\n",
       "cell_1996  cluster_101  subclass_10  class_1\n",
       "cell_1997  cluster_000  subclass_00  class_0\n",
       "cell_1998  cluster_010  subclass_01  class_0\n",
       "cell_1999  cluster_000  subclass_00  class_0\n",
       "\n",
       "[2000 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src.obs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b00575-02dc-4b5b-ba66-761c7a5ec0e4",
   "metadata": {},
   "source": [
    "The `obs` dataframe contains a unique label for each cell as well as its assigned cell type at each level in our taxonomy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf92746-1c2a-491f-b8a2-2e0b94bee21b",
   "metadata": {},
   "source": [
    "# 2 -- Select marker genes from our cartoon reference data\n",
    "\n",
    "The entire purpose of this section of the notebook is to describe how to produce a JSON lookup table of marker genes from the cartoon reference data we just created. Marker gene selection is an ongoing research question, if you have a preferred way of selecting marker genes, all you have to do is encode your marker genes in a JSON file that comports with the schema documented [on this page](https://github.com/AllenInstitute/cell_type_mapper/blob/main/docs/input_data_files/marker_gene_lookup.md) and you will be able to run your markers through the `cell_type_mapper`. This section of the notebook is only useful if you want to use the tools in the `cell_type_mapper` to do the marker gene selection for you.\n",
    "\n",
    "## Selecting marker genes using command line tools\n",
    "\n",
    "In the cells below we will invoke the command line tools to create a set of marker genes for mapping to our reference dataset. The `!` at the start of each cell tells Jupyter that the cell is a command to be executed in the shell, i.e. these shells contain the commands you should invoke from the command line to select marker genes.\n",
    "\n",
    "**Note:** to see the full call signatures of any of the tools below, replace the command line arguments with `--help`, i.e.\n",
    "```\n",
    "python -m cell_type_mapper.cli.reference_markers --help\n",
    "```\n",
    "will show documentation for the full call signature for the `reference_markers` tool. Most of the command line arguments for the tools in question have sensible defaults. We will explain the arguments we set to non-default values below.\n",
    "\n",
    "### Precompute statistics\n",
    "\n",
    "The first step is to create the precomputed statisitcs file for the reference data. This is an HDF5 file that contains, essentially, the mean gene expression profile of every cell type in the taxonomy. It also contains an encoding of the cell type taxonomy. The detailed contents of this file are documented [on this page](https://github.com/AllenInstitute/cell_type_mapper/blob/main/docs/input_data_files/precomputed_stats_file.md).\n",
    "\n",
    "The call signature for the tool used below can be accessed by running `python -m cell_type_mapper.cli.precompute_stats_scrattch --help`. Most of the arguments are set to sensible defaults. The arguments we are explicitly setting below are:\n",
    "\n",
    "- `heirarchy`: a list specifying the inheritance order from most gross to most fine of the levels in our cell type taxonomy (note the nested set of quotations around the cell types and the square brackets). These must be the names of columns in the `obs` dataframe of the reference data.\n",
    "- `h5ad_path`: the path to the h5ad file containing the reference data for the taxonomy\n",
    "- `n_processors`: the number of independent worker processes to spin up\n",
    "- `normalization`: either `raw` or `log2CPM` indicating whether the data in the input h5ad file is in raw counts or `log2(CPM+1)` normalization.\n",
    "- `clobber`: if False and the file specified by `output_path` already exists, the code will fail before doing anything. If `True`, and the output file already exists, the output file willb e overwritten\n",
    "- `output_path`: the path to the HDF5 file that will be written out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "004b58d1-d472-42cb-b6ed-754ee4a3eff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finally process 42347 tot 2.15e-02 reading 3.86e-04 writing 1.23e-03\n"
     ]
    }
   ],
   "source": [
    "!python -m cell_type_mapper.cli.precompute_stats_scrattch \\\n",
    "--hierarchy '[\"class\", \"subclass\", \"cluster\"]' \\\n",
    "--h5ad_path pipeline_example_data/training_data.h5ad \\\n",
    "--n_processors 3 \\\n",
    "--normalization raw \\\n",
    "--clobber True \\\n",
    "--output_path pipeline_example_data/precomputed_stats.h5 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a73c9c-92e8-4aa7-976f-d78ee5a2d193",
   "metadata": {},
   "source": [
    "### Select reference markers\n",
    "\n",
    "The next step is to select \"reference markers.\" This is essentially identifying all of the marker genes between all of the pairs of cell types that exist in our taxonomy. This step can be expensive (taking several hours for a taxonomy with several thousand taxons in it) and creates a very large file (10s of GB for a taxonomy with several thousand taxons in it). However, in theory, it only needs to be run once for a specific reference dataset.\n",
    "\n",
    "A later step, query marker selection, downselects this set of marker genes to find an optimal and minial combination of marker genes given the unlabeled dataset at hand. That step takes the output of this step as an input.\n",
    "\n",
    "One quirk of the `reference_marker` tool is that it does not let you specify an output file, only an output directory. This design is meant to support use cases where multiple experimental apparatuses (e.g. 10Xv3, 10Xv2, 10XMulti) are used to take data for the same reference dataset. The idea is that the data from each apparatus would be treated indpendently through the `precomputed_stats` and `reference_markers` steps, and then joined during query marker selection (the next step) into a single set of query markers. This level of detail is likely overkill for most users. The name of the file written by this tool is printed out to `stdout` during running. Look for a file named like `reference_markers.h5` in your specified output directory. For those worried about overwriting previous results, if you do not run with `--clobber True`, the tool will crash rather than overwrite an existing file. \n",
    "\n",
    "There are many unexercised arguments to this function (again, because they default to reasonable values) in the example below. These control the statistical definition of what counts as a marker gene. They are documented [on this page](https://github.com/AllenInstitute/cell_type_mapper/blob/main/docs/algorithms/marker_gene_selection.md). The arguments we are specifying below are\n",
    "- `precomputed_path_list`: a list of paths to precomputed statistics files (i.e. the output of `precompute_stats_scrattch` above). For each of these files, a different reference marker file will be written out for reasons described above (multiple apparatuses; one taxonomy). Note the nested quotation marks surrounding the list.\n",
    "- `n_valid`: the code has strict criteria which a gene must meet to be considered a marker for discriminating between two cell types. Some data is so noisy, however, that, for some pairs of cell types, very few genes will satisfy these strict criteria. [The algorithm](https://github.com/AllenInstitute/cell_type_mapper/blob/main/docs/algorithms/marker_gene_selection.md) will gradually relax the criteria so that any given pair of cell types has at least `n_valid` markers discriminating between them.\n",
    "- `output_dir`: the directory to which the reference marker files will be written (see discussion above for why the output destination is specified this way)\n",
    "- `clobber`: if running the code would overwrite an existing file, the code will fail before doing anything. Set `--clobber True` to go ahead and overwrite te file anyway.\n",
    "\n",
    "There is one argument we did not set that we would like to draw attention to\n",
    "- `query_path`: the path to the h5ad file specifying the unlabeled data that will ultimately be mapped. If you specify this argument, then the marker genes will only be selected from those genes that are present in the `var` dataframe of the corresponding file. If you do not specify this argument, then any genes in the precomputed stats file are considered valid choices as marker genes. Specifying the `query_path` can be helpful in preventing the code from placing too much stock in a very distinct set of marker genes that end up not being useful because they are not present in the unlabeled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2be32682-257c-486d-bae2-410e683db62f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing pipeline_example_data/reference_markers.h5\n",
      "Starting precomputed_stats.h5\n",
      "16 of 28 taxon pairs in 1.83e+00 sec; predict 1.37e+00 sec of 3.20e+00 sec left\n",
      "24 of 28 taxon pairs in 1.83e+00 sec; predict 3.06e-01 sec of 2.14e+00 sec left\n",
      "32 of 28 taxon pairs in 3.25e+00 sec; predict -4.06e-01 sec of 2.84e+00 sec left\n",
      "Initial marker discovery took 3.27e+00 seconds\n",
      "joining took 4.981041e-03 seconds\n",
      "joining took 4.846096e-03 seconds\n",
      "Transposing markers took 3.28e+00 seconds\n",
      "Copying to pipeline_example_data/reference_markers.h5 took 2.15e-04 seconds\n",
      "Wrote reference_markers.h5\n",
      "REFERENCE MARKER FINDER RAN SUCCESSFULLY\n",
      "completed in 6.55e+00 seconds\n"
     ]
    }
   ],
   "source": [
    "!python -m cell_type_mapper.cli.reference_markers \\\n",
    "--precomputed_path_list \"['pipeline_example_data/precomputed_stats.h5']\" \\\n",
    "--n_valid 20 \\\n",
    "--n_processors 3 \\\n",
    "--output_dir pipeline_example_data \\\n",
    "--clobber True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9a9c51-2d60-4ebf-baab-567f4e1a5356",
   "metadata": {},
   "source": [
    "### Select query markers\n",
    "\n",
    "The final step in marker selection is to downsample the `reference_markers` file to find a minimal set of markers to be used during the cell type mapping. This is a much quicker step than `reference_marker` finding, and produces a JSON file that maps between cell types in our taxonomy tree and marker genes that are used to discriminate between those cell types' children as discussed [on this page](https://github.com/AllenInstitute/cell_type_mapper/blob/main/docs/input_data_files/marker_gene_lookup.md).\n",
    "\n",
    "The arguments we are using below are\n",
    "- `reference_marker_path_list`: the list of the paths of the reference marker files (i.e. the HDF5 files produced by the `reference_marker` tool above) from which these query markers are to be sampled. For the same reason that the reference marker finder specifies only an output directory, this function takes a list of reference marker files. This is the step where multiple reference markers for multiple experimental apparatuses could theoretically be joined into a single marker gene lookup table.\n",
    "- `n_per_utility`: for each pair of cell type taxons `A` and `B`, there are two \"utilities\" a marker gene can serve: \"up regulated in A\" and \"up regulated in B.\" The query marker finder will do its best to select `n_per_utility` genes that are markers *and* are up regulated in A and `n_per_utility` genes that are markers *and* are up regulated in B (assuming that many markers exist in the reference marker file).\n",
    "- `n_processors`: the number of independent worker processes to spin up while selecting markers.\n",
    "\n",
    "There is two areguments we are not using below which it is worth taking note of:\n",
    "- `search_for_stats_file`: technically, the query marker selecter needs the reference marker file and the precomputed stats file associated with it. The path to the precomputed stats file used in generating the reference marker file is encoded in the metadata stored in the reference marker file. If, for some reason, you files have moved from their original locations (for instance, if you are working in a cloud computing environment), you can set `--search_for_stats_file True` and the query marker finder will look for the precomputed stats file in the same directory that contains the reference marker file.\n",
    "- `query_path`: the path to the h5ad file specifying the unlabeled data that will ultimately be mapped. If you specify this argument, then the marker genes will only be selected from those genes that are present in the `var` dataframe of the corresponding file. If you do not specify this argument, then any genes in the reference marker file are considered valid choices as marker genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74487bda-b6fe-4408-b6f1-10adbc90ad73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found markers for 1 parents in 2.48e-02 minutes; predict 1.99e-01 of 2.23e-01 remaining\n",
      "found markers for 4 parents in 2.52e-02 minutes; predict 3.15e-02 of 5.67e-02 remaining\n",
      "found markers for 5 parents in 5.12e-02 minutes; predict 4.09e-02 of 9.21e-02 remaining\n",
      "QUERY MARKER FINDER RAN SUCCESSFULLY in 4.41e+00 seconds\n"
     ]
    }
   ],
   "source": [
    "!python -m cell_type_mapper.cli.query_markers \\\n",
    "--output_path pipeline_example_data/query_markers.json \\\n",
    "--reference_marker_path_list '[\"pipeline_example_data/reference_markers.h5\"]' \\\n",
    "--n_per_utility 10 \\\n",
    "--n_processors 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b389522-108f-4c81-8e46-8b5dfa3f204c",
   "metadata": {},
   "source": [
    "## Selecting marker genes programmatically\n",
    "\n",
    "In the cell below, we will demonstrate how to run the same commands from within a python script, for those who would rather work directly in python than invoke command-line tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e5a96fc-ecfd-4d40-b633-c3cc582c5aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finally process 42399 tot 2.84e-02 reading 1.16e-03 writing 1.98e-03\n",
      "\n",
      "====done with precomputed_stats====\n",
      "\n",
      "writing pipeline_example_data/reference_markers.h5\n",
      "Starting precomputed_stats.h5\n",
      "8 of 28 taxon pairs in 1.23e+00 sec; predict 3.08e+00 sec of 4.31e+00 sec left\n",
      "16 of 28 taxon pairs in 1.24e+00 sec; predict 9.27e-01 sec of 2.16e+00 sec left\n",
      "24 of 28 taxon pairs in 1.24e+00 sec; predict 2.06e-01 sec of 1.44e+00 sec left\n",
      "32 of 28 taxon pairs in 1.25e+00 sec; predict -1.56e-01 sec of 1.09e+00 sec left\n",
      "Initial marker discovery took 1.27e+00 seconds\n",
      "joining took 2.536392e-02 seconds\n",
      "joining took 2.878022e-02 seconds\n",
      "Transposing markers took 3.06e+00 seconds\n",
      "Copying to pipeline_example_data/reference_markers.h5 took 1.51e-04 seconds\n",
      "Wrote reference_markers.h5\n",
      "REFERENCE MARKER FINDER RAN SUCCESSFULLY\n",
      "completed in 4.34e+00 seconds\n",
      "\n",
      "====done with reference_markers====\n",
      "\n",
      "found markers for 1 parents in 1.31e-02 minutes; predict 1.05e-01 of 1.18e-01 remaining\n",
      "found markers for 4 parents in 1.35e-02 minutes; predict 1.69e-02 of 3.04e-02 remaining\n",
      "found markers for 5 parents in 2.75e-02 minutes; predict 2.20e-02 of 4.95e-02 remaining\n",
      "QUERY MARKER FINDER RAN SUCCESSFULLY in 1.78e+00 seconds\n"
     ]
    }
   ],
   "source": [
    "from cell_type_mapper.cli.precompute_stats_scrattch import (\n",
    "    PrecomputationScrattchRunner)\n",
    "\n",
    "from cell_type_mapper.cli.reference_markers import (\n",
    "    ReferenceMarkerRunner\n",
    ")\n",
    "\n",
    "from cell_type_mapper.cli.query_markers import (\n",
    "    QueryMarkerRunner\n",
    ")\n",
    "\n",
    "precomputation_config = {\n",
    "    'hierarchy': ['class', 'subclass', 'cluster'],\n",
    "    'h5ad_path': 'pipeline_example_data/training_data.h5ad',\n",
    "    'output_path': 'pipeline_example_data/precomputed_stats.h5ad',\n",
    "    'n_processors': 3,\n",
    "    'normalization': 'raw',\n",
    "    'clobber': True\n",
    "}\n",
    "\n",
    "# the args=[] is important to prevent the PrecomputationScrattchRunner from grabbing\n",
    "# any command line arguments when you invoke your python script\n",
    "precomputation_runner = PrecomputationScrattchRunner(\n",
    "    args=[], input_data=precomputation_config)\n",
    "\n",
    "precomputation_runner.run()\n",
    "\n",
    "print('\\n====done with precomputed_stats====\\n')\n",
    "\n",
    "reference_config = {\n",
    "    'precomputed_path_list': ['pipeline_example_data/precomputed_stats.h5'],\n",
    "    'n_valid': 20,\n",
    "    'output_dir': 'pipeline_example_data',\n",
    "    'clobber': True\n",
    "}\n",
    "\n",
    "reference_runner = ReferenceMarkerRunner(\n",
    "    args=[], input_data=reference_config)\n",
    "\n",
    "reference_runner.run()\n",
    "\n",
    "print('\\n====done with reference_markers====\\n')\n",
    "\n",
    "\n",
    "query_config = {\n",
    "    'output_path': 'pipeline_example_data/query_markers.json',\n",
    "    'reference_marker_path_list': ['pipeline_example_data/reference_markers.h5'],\n",
    "    'n_per_utility': 10,\n",
    "    'n_processors': 3\n",
    "}\n",
    "\n",
    "query_runner = QueryMarkerRunner(\n",
    "    args=[], input_data=query_config)\n",
    "\n",
    "query_runner.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa9c461-3ea7-4a2d-8238-44714a5a7c2e",
   "metadata": {},
   "source": [
    "# 3 -- Create unlabeled data\n",
    "\n",
    "Let's create a small h5ad file of unlabeled data. For each cluster, we will create one cell which is a linear combination of the chosen cluster with a small (0.05) contribution from another cluster. This will introduce some noise into the mapping an allow us to examine the ways in which the `cell_type_mapper` encodes uncertainty in its mappings. Since we are only creating one cartoon cell per cluster, we will identify each cell according to the cluster we know it \"should\" belong to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a32629d4-d25e-4838-9335-ec371dd905d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(77121133)\n",
    "\n",
    "n_cells = 12\n",
    "obs_data = []\n",
    "cell_by_gene = []\n",
    "for cluster in cluster_names:\n",
    "    this_obs = {'cell_id': cluster}\n",
    "    obs_data.append(this_obs)\n",
    "    if cluster != 'cluster_200':\n",
    "        other_cluster = 'cluster_200'\n",
    "    else:\n",
    "        other_cluster = 'cluster_000'\n",
    "\n",
    "    this_cell = create_noisy_cell(\n",
    "        taxon_to_wgt={cluster: 0.95, other_cluster: 0.05},\n",
    "        rng=rng\n",
    "    )\n",
    "    cell_by_gene.append(this_cell)\n",
    "\n",
    "cell_by_gene = np.array(cell_by_gene)\n",
    "obs = pd.DataFrame(obs_data).set_index('cell_id')\n",
    "\n",
    "a_data = anndata.AnnData(\n",
    "    obs=obs,\n",
    "    var=var,\n",
    "    X=cell_by_gene)\n",
    "\n",
    "unlabeled_path = pathlib.Path('pipeline_example_data/unlabeled.h5ad')\n",
    "if unlabeled_path.exists():\n",
    "    unlabeled_path.unlink()\n",
    "a_data.write_h5ad(unlabeled_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93863708-fb80-4109-85b6-28ef6f5f99c3",
   "metadata": {},
   "source": [
    "# 4 -- Map the unlabeled data using the command line tool\n",
    "\n",
    "We wrote our unlabeled data to `pipeline_example/unlabeled.h5ad`.\n",
    "\n",
    "Below is the command to perform the cell type mapping using the command line tool. The arguments for that tool are documented [on this page](https://github.com/AllenInstitute/cell_type_mapper/blob/main/docs/mapping_cells.md#mapping-unlabeled-data-onto-the-reference-taxonomy). The arguments we are using below are\n",
    "- `precomputed_stats.path`: the path to the HDF5 file containing the precomputed statistics for our taxonomy (i.e. the output of the `precompute_stats_scrattch` tool above)\n",
    "- `query_markers.serialized_lookup`: the path to the JSON file containing the marker gene lookup table (i.e. the output of the `query_markers` tool above)\n",
    "- `type_assignment.bootstrap_factor`: the factor by which to randomly downsample the full marker gene list at each [maapping iteration](https://github.com/AllenInstitute/cell_type_mapper/blob/main/docs/algorithms/hierarchical_mapping.md)\n",
    "- `type_assignment.bootstrap_iteration`: the number of mapping iterations to perform at each level of the taxonomy\n",
    "- `type_assignment.rng_seed`: the seed for the random number generator. This is specified as an argument so that two runs with the same configuration produce identical results (rather than depending on the vagaries of a random number generator seeded from the system clock)\n",
    "- `type_assignment.n_processors`: the number of independent worker processes to spin up while mapping.\n",
    "- `query_path`: the path to the h5ad file containing the unlabeled data (i.e. the cell-by-gene data for the cells you would like to map onto this taxonomy).\n",
    "- `extended_result_path`: the path to the JSON file where mapping results will be written.\n",
    "- `csv_result_path`: the path to the CSV file where mapping results will be written."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ae203e6-c272-4cd9-80df-a6b2586b55f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Running Hierarchical Mapping v1.4.1 with config ===\n",
      "{\n",
      "  \"query_markers\": {\n",
      "    \"log_level\": \"ERROR\",\n",
      "    \"serialized_lookup\": \"pipeline_example_data/query_markers.json\"\n",
      "  },\n",
      "  \"summary_metadata_path\": null,\n",
      "  \"verbose_csv\": false,\n",
      "  \"verbose_stdout\": true,\n",
      "  \"flatten\": false,\n",
      "  \"drop_level\": null,\n",
      "  \"tmp_dir\": null,\n",
      "  \"log_path\": null,\n",
      "  \"precomputed_stats\": {\n",
      "    \"log_level\": \"ERROR\",\n",
      "    \"path\": \"pipeline_example_data/precomputed_stats.h5\"\n",
      "  },\n",
      "  \"max_gb\": 100.0,\n",
      "  \"csv_result_path\": \"pipeline_example_data/mapping_output.csv\",\n",
      "  \"map_to_ensembl\": false,\n",
      "  \"obsm_key\": null,\n",
      "  \"type_assignment\": {\n",
      "    \"n_processors\": 1,\n",
      "    \"normalization\": \"raw\",\n",
      "    \"chunk_size\": 10000,\n",
      "    \"bootstrap_factor\": 0.5,\n",
      "    \"bootstrap_factor_lookup\": null,\n",
      "    \"rng_seed\": 661123,\n",
      "    \"n_runners_up\": 5,\n",
      "    \"min_markers\": 10,\n",
      "    \"bootstrap_iteration\": 100,\n",
      "    \"log_level\": \"ERROR\"\n",
      "  },\n",
      "  \"nodes_to_drop\": null,\n",
      "  \"extended_result_dir\": null,\n",
      "  \"query_path\": \"pipeline_example_data/unlabeled.h5ad\",\n",
      "  \"extended_result_path\": \"pipeline_example_data/mapping_output.json\",\n",
      "  \"obsm_clobber\": false,\n",
      "  \"log_level\": \"ERROR\",\n",
      "  \"hdf5_result_path\": null,\n",
      "  \"cloud_safe\": false\n",
      "}\n",
      "ENV: is_torch_available: False\n",
      "ENV: is_cuda_available: False\n",
      "ENV: use_torch: False\n",
      "ENV: multiprocessing start method: spawn\n",
      "ENV: Python version: 3.10.15 (main, Oct  3 2024, 02:33:33) [Clang 14.0.6 ]\n",
      "ENV: anndata version: 0.11.1\n",
      "ENV: numpy version: 2.2.1\n",
      "BENCHMARK: spent 3.6693e-04 seconds validating config and copying data\n",
      "using ../precomputed_stats.h5 for precomputed_stats\n",
      "reading taxonomy_tree from ../precomputed_stats.h5\n",
      "/Users/scott.daniel/KnowledgeBase/knowledge_graph_prototypes/src/cell_type_mapper/taxonomy/utils.py:245: UserWarning: This taxonomy has no mapping from leaf_node -> rows in the cell by gene matrix\n",
      "  warnings.warn(\"This taxonomy has no mapping from leaf_node -> rows \"\n",
      "BENCHMARK: spent 9.0551e-03 seconds creating query marker cache\n",
      "Running CPU implementation of type assignment.\n",
      "8 of 8 cells in 1.62e+00 sec; predict 0.00e+00 sec of 1.62e+00 sec left\n",
      "BENCHMARK: spent 1.6391e+00 seconds assigning cell types\n",
      "Writing marker genes to output file\n",
      "MAPPING FROM SPECIFIED MARKERS RAN SUCCESSFULLY\n",
      "CLEANING UP\n"
     ]
    }
   ],
   "source": [
    "!python -m cell_type_mapper.cli.from_specified_markers \\\n",
    "--precomputed_stats.path pipeline_example_data/precomputed_stats.h5 \\\n",
    "--query_markers.serialized_lookup pipeline_example_data/query_markers.json \\\n",
    "--type_assignment.bootstrap_factor 0.5 \\\n",
    "--type_assignment.bootstrap_iteration 100 \\\n",
    "--type_assignment.rng_seed 661123 \\\n",
    "--type_assignment.n_processors 1 \\\n",
    "--type_assignment.normalization raw \\\n",
    "--query_path pipeline_example_data/unlabeled.h5ad \\\n",
    "--extended_result_path pipeline_example_data/mapping_output.json \\\n",
    "--csv_result_path pipeline_example_data/mapping_output.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11866dad-4188-4947-b2af-62c0022e83a7",
   "metadata": {},
   "source": [
    "# 4.1 -- Map the unlabeled dataset programmatically\n",
    "\n",
    "Here we show how to perform the same mapping from within a python script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22537da1-402d-49f0-b6bf-5dada67d75f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Running Hierarchical Mapping v1.4.1 with config ===\n",
      "{\n",
      "  \"obsm_key\": null,\n",
      "  \"verbose_stdout\": true,\n",
      "  \"type_assignment\": {\n",
      "    \"min_markers\": 10,\n",
      "    \"n_processors\": 1,\n",
      "    \"n_runners_up\": 5,\n",
      "    \"chunk_size\": 10000,\n",
      "    \"bootstrap_iteration\": 100,\n",
      "    \"log_level\": \"ERROR\",\n",
      "    \"bootstrap_factor_lookup\": null,\n",
      "    \"bootstrap_factor\": 0.5,\n",
      "    \"rng_seed\": 661123,\n",
      "    \"normalization\": \"raw\"\n",
      "  },\n",
      "  \"query_path\": \"pipeline_example_data/unlabeled.h5ad\",\n",
      "  \"tmp_dir\": null,\n",
      "  \"extended_result_dir\": null,\n",
      "  \"log_level\": \"ERROR\",\n",
      "  \"precomputed_stats\": {\n",
      "    \"path\": \"pipeline_example_data/precomputed_stats.h5\",\n",
      "    \"log_level\": \"ERROR\"\n",
      "  },\n",
      "  \"verbose_csv\": false,\n",
      "  \"query_markers\": {\n",
      "    \"serialized_lookup\": \"pipeline_example_data/query_markers.json\",\n",
      "    \"log_level\": \"ERROR\"\n",
      "  },\n",
      "  \"drop_level\": null,\n",
      "  \"summary_metadata_path\": null,\n",
      "  \"max_gb\": 100.0,\n",
      "  \"flatten\": false,\n",
      "  \"cloud_safe\": false,\n",
      "  \"log_path\": null,\n",
      "  \"map_to_ensembl\": false,\n",
      "  \"csv_result_path\": \"pipeline_example_data/mapping_output.csv\",\n",
      "  \"obsm_clobber\": false,\n",
      "  \"hdf5_result_path\": null,\n",
      "  \"extended_result_path\": \"pipeline_example_data/mapping_output.json\",\n",
      "  \"nodes_to_drop\": null\n",
      "}\n",
      "ENV: is_torch_available: False\n",
      "ENV: is_cuda_available: False\n",
      "ENV: use_torch: False\n",
      "ENV: multiprocessing start method: spawn\n",
      "ENV: Python version: 3.10.15 (main, Oct  3 2024, 02:33:33) [Clang 14.0.6 ]\n",
      "ENV: anndata version: 0.11.1\n",
      "ENV: numpy version: 2.2.1\n",
      "BENCHMARK: spent 4.3321e-04 seconds validating config and copying data\n",
      "using ../precomputed_stats.h5 for precomputed_stats\n",
      "reading taxonomy_tree from ../precomputed_stats.h5\n",
      "BENCHMARK: spent 1.0538e-02 seconds creating query marker cache\n",
      "Running CPU implementation of type assignment.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/scott.daniel/KnowledgeBase/knowledge_graph_prototypes/src/cell_type_mapper/taxonomy/utils.py:245: UserWarning: This taxonomy has no mapping from leaf_node -> rows in the cell by gene matrix\n",
      "  warnings.warn(\"This taxonomy has no mapping from leaf_node -> rows \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 of 8 cells in 7.01e-01 sec; predict 0.00e+00 sec of 7.01e-01 sec left\n",
      "BENCHMARK: spent 7.2295e-01 seconds assigning cell types\n",
      "Writing marker genes to output file\n",
      "MAPPING FROM SPECIFIED MARKERS RAN SUCCESSFULLY\n",
      "CLEANING UP\n"
     ]
    }
   ],
   "source": [
    "from cell_type_mapper.cli.from_specified_markers import (\n",
    "    FromSpecifiedMarkersRunner\n",
    ")\n",
    "\n",
    "config = {\n",
    "    'precomputed_stats': {\n",
    "        'path': 'pipeline_example_data/precomputed_stats.h5'\n",
    "    },\n",
    "    'query_markers': {\n",
    "        'serialized_lookup': 'pipeline_example_data/query_markers.json'\n",
    "    },\n",
    "    'type_assignment': {\n",
    "        'bootstrap_factor': 0.5,\n",
    "        'bootstrap_iteration': 100,\n",
    "        'rng_seed': 661123,\n",
    "        'n_processors': 1,\n",
    "        'normalization': 'raw'\n",
    "    },\n",
    "    'query_path': 'pipeline_example_data/unlabeled.h5ad',\n",
    "    'extended_result_path': 'pipeline_example_data/mapping_output.json',\n",
    "    'csv_result_path': 'pipeline_example_data/mapping_output.csv'\n",
    "}\n",
    "\n",
    "mapping_runner = FromSpecifiedMarkersRunner(\n",
    "    args=[], input_data=config)\n",
    "\n",
    "mapping_runner.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40098029-c657-462e-ab51-b38af0851fa2",
   "metadata": {},
   "source": [
    "# 5 -- Examining the outputs of the mapping\n",
    "\n",
    "We wrote the outputs of the mapping in two forms, a CSV file at `pipeline_example_data/mapping_output.csv` and a JSON file at `pipeline_example_data/mapping_output.json`. The contents of these files are documented [on this page](https://github.com/AllenInstitute/cell_type_mapper/blob/main/docs/output.md).\n",
    "\n",
    "## The CSV output file\n",
    "\n",
    "The CSV file is the simplest output file, so we will examine that first.\n",
    "\n",
    "**Note:** most of the work below is redundant with what is discussed in [this notebook](https://github.com/AllenInstitute/cell_type_mapper/blob/main/examples/explore_mapping_results.ipynb), which creates an h5ad file of real data and shows users how to run it through the on-line MapMyCells interface, download the results, and inspect them. Here, we will go into a little more discussion about the probabilistic nature of the cell type mapping, since we had direct control over both the cell type taxonomy and the unlabeled data.\n",
    "\n",
    "The CSV file can be read in with pands, provided you instruct pandas to ignore all lines that start with `#`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e301148a-38cf-4fac-a323-6a01285417b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.read_csv('pipeline_example_data/mapping_output.csv', comment='#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "279ad493-0916-41f3-88dd-cd0b1901bfe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_id</th>\n",
       "      <th>class_label</th>\n",
       "      <th>class_name</th>\n",
       "      <th>class_bootstrapping_probability</th>\n",
       "      <th>subclass_label</th>\n",
       "      <th>subclass_name</th>\n",
       "      <th>subclass_bootstrapping_probability</th>\n",
       "      <th>cluster_label</th>\n",
       "      <th>cluster_name</th>\n",
       "      <th>cluster_alias</th>\n",
       "      <th>cluster_bootstrapping_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cluster_000</td>\n",
       "      <td>class_0</td>\n",
       "      <td>class_0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>subclass_00</td>\n",
       "      <td>subclass_00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>cluster_000</td>\n",
       "      <td>cluster_000</td>\n",
       "      <td>cluster_000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cluster_001</td>\n",
       "      <td>class_0</td>\n",
       "      <td>class_0</td>\n",
       "      <td>0.93</td>\n",
       "      <td>subclass_00</td>\n",
       "      <td>subclass_00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>cluster_001</td>\n",
       "      <td>cluster_001</td>\n",
       "      <td>cluster_001</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cluster_010</td>\n",
       "      <td>class_0</td>\n",
       "      <td>class_0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>subclass_01</td>\n",
       "      <td>subclass_01</td>\n",
       "      <td>0.72</td>\n",
       "      <td>cluster_010</td>\n",
       "      <td>cluster_010</td>\n",
       "      <td>cluster_010</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cluster_011</td>\n",
       "      <td>class_0</td>\n",
       "      <td>class_0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>subclass_01</td>\n",
       "      <td>subclass_01</td>\n",
       "      <td>1.00</td>\n",
       "      <td>cluster_011</td>\n",
       "      <td>cluster_011</td>\n",
       "      <td>cluster_011</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cluster_100</td>\n",
       "      <td>class_1</td>\n",
       "      <td>class_1</td>\n",
       "      <td>0.60</td>\n",
       "      <td>subclass_10</td>\n",
       "      <td>subclass_10</td>\n",
       "      <td>0.58</td>\n",
       "      <td>cluster_100</td>\n",
       "      <td>cluster_100</td>\n",
       "      <td>cluster_100</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cluster_101</td>\n",
       "      <td>class_1</td>\n",
       "      <td>class_1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>subclass_10</td>\n",
       "      <td>subclass_10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>cluster_101</td>\n",
       "      <td>cluster_101</td>\n",
       "      <td>cluster_101</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cluster_110</td>\n",
       "      <td>class_1</td>\n",
       "      <td>class_1</td>\n",
       "      <td>0.93</td>\n",
       "      <td>subclass_11</td>\n",
       "      <td>subclass_11</td>\n",
       "      <td>0.73</td>\n",
       "      <td>cluster_110</td>\n",
       "      <td>cluster_110</td>\n",
       "      <td>cluster_110</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cluster_200</td>\n",
       "      <td>class_2</td>\n",
       "      <td>class_2</td>\n",
       "      <td>0.74</td>\n",
       "      <td>subclass_20</td>\n",
       "      <td>subclass_20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>cluster_200</td>\n",
       "      <td>cluster_200</td>\n",
       "      <td>cluster_200</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cell_id class_label class_name  class_bootstrapping_probability  \\\n",
       "0  cluster_000     class_0    class_0                             1.00   \n",
       "1  cluster_001     class_0    class_0                             0.93   \n",
       "2  cluster_010     class_0    class_0                             0.85   \n",
       "3  cluster_011     class_0    class_0                             0.92   \n",
       "4  cluster_100     class_1    class_1                             0.60   \n",
       "5  cluster_101     class_1    class_1                             1.00   \n",
       "6  cluster_110     class_1    class_1                             0.93   \n",
       "7  cluster_200     class_2    class_2                             0.74   \n",
       "\n",
       "  subclass_label subclass_name  subclass_bootstrapping_probability  \\\n",
       "0    subclass_00   subclass_00                                1.00   \n",
       "1    subclass_00   subclass_00                                1.00   \n",
       "2    subclass_01   subclass_01                                0.72   \n",
       "3    subclass_01   subclass_01                                1.00   \n",
       "4    subclass_10   subclass_10                                0.58   \n",
       "5    subclass_10   subclass_10                                1.00   \n",
       "6    subclass_11   subclass_11                                0.73   \n",
       "7    subclass_20   subclass_20                                1.00   \n",
       "\n",
       "  cluster_label cluster_name cluster_alias  cluster_bootstrapping_probability  \n",
       "0   cluster_000  cluster_000   cluster_000                               1.00  \n",
       "1   cluster_001  cluster_001   cluster_001                               0.98  \n",
       "2   cluster_010  cluster_010   cluster_010                               1.00  \n",
       "3   cluster_011  cluster_011   cluster_011                               1.00  \n",
       "4   cluster_100  cluster_100   cluster_100                               1.00  \n",
       "5   cluster_101  cluster_101   cluster_101                               1.00  \n",
       "6   cluster_110  cluster_110   cluster_110                               1.00  \n",
       "7   cluster_200  cluster_200   cluster_200                               1.00  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0c17d0-5cee-400c-ba0e-c1f662fb0588",
   "metadata": {},
   "source": [
    "Inspecting this CSV we see that\n",
    "\n",
    "- Every cell was ultimately assigned to the expected cluster (i.e. `cell_id` is identical to `cluster_label`.\n",
    "- In some cases, the `cell_type_mapper` was not absolutely confident in its assignments (`bootstrapping_probability < 1.0`), this being a reflection of the noise we introduced by making each cell a linear combination of two cell type characteristic profiles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260b858e-5776-4988-b6ca-7882f13480d7",
   "metadata": {},
   "source": [
    "## The JSON output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2b623b3-6a09-4b3f-8841-c6300e88e3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pipeline_example_data/mapping_output.json', 'rb') as src:\n",
    "    json_results = json.load(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e54093-439d-4b84-8ef7-d64eaf419331",
   "metadata": {},
   "source": [
    "As discussed [in this notebook](https://github.com/AllenInstitute/cell_type_mapper/blob/main/examples/explore_mapping_results.ipynb), the JSON output file contains a great deal of metadata about the specific `cell_type_mapper` run. You should consult that notebook for a guided tour of those metadata products. Here we will focus on the actual cell type mapping results contained under the `'results'` key. Let's look at one cell in particular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f79071c1-bccf-4dbd-8882-f414e05e7abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"class\": {\n",
      "    \"assignment\": \"class_0\",\n",
      "    \"bootstrapping_probability\": 0.85,\n",
      "    \"avg_correlation\": 0.6718937427632787,\n",
      "    \"runner_up_assignment\": [\n",
      "      \"class_2\",\n",
      "      \"class_1\"\n",
      "    ],\n",
      "    \"runner_up_correlation\": [\n",
      "      0.5817858149210493,\n",
      "      0.6141052482383532\n",
      "    ],\n",
      "    \"runner_up_probability\": [\n",
      "      0.11,\n",
      "      0.04\n",
      "    ],\n",
      "    \"aggregate_probability\": 0.85,\n",
      "    \"directly_assigned\": true\n",
      "  },\n",
      "  \"subclass\": {\n",
      "    \"assignment\": \"subclass_01\",\n",
      "    \"bootstrapping_probability\": 0.72,\n",
      "    \"avg_correlation\": 0.8383194712020221,\n",
      "    \"runner_up_assignment\": [\n",
      "      \"subclass_00\"\n",
      "    ],\n",
      "    \"runner_up_correlation\": [\n",
      "      0.7740023346260767\n",
      "    ],\n",
      "    \"runner_up_probability\": [\n",
      "      0.28\n",
      "    ],\n",
      "    \"aggregate_probability\": 0.612,\n",
      "    \"directly_assigned\": true\n",
      "  },\n",
      "  \"cluster\": {\n",
      "    \"assignment\": \"cluster_010\",\n",
      "    \"bootstrapping_probability\": 1.0,\n",
      "    \"avg_correlation\": 0.9919515262402204,\n",
      "    \"runner_up_assignment\": [],\n",
      "    \"runner_up_correlation\": [],\n",
      "    \"runner_up_probability\": [],\n",
      "    \"aggregate_probability\": 0.612,\n",
      "    \"directly_assigned\": true\n",
      "  },\n",
      "  \"cell_id\": \"cluster_010\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(json_results['results'][2], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5dae78-8b9d-4b08-a87c-60c4b086a928",
   "metadata": {},
   "source": [
    "The cell is represented by a dict whose keys are the levels in our cartoon cell type taxonomy (except for `cell_id`, which maps to the unique identifier of this cell). For each level of the taxonomy, we see have\n",
    "- The cell type to which the cell was actually assigned\n",
    "- The fraction of mapping iterations that made that assignment (the `bootstrapping_probability`)\n",
    "- The average correlation coefficient between the cell and the assigned cell type (the `avg_correlation`)\n",
    "- A list of the cell types to which the cell might have been assigned but wasn't, along with their `bootstrapping_probability` and `avg_correlation` scores.\n",
    "\n",
    "For instance, looking at the `class` level for our example cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d96998de-b803-4cd2-b3ba-e346a44908a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"assignment\": \"class_0\",\n",
      "  \"bootstrapping_probability\": 0.85,\n",
      "  \"avg_correlation\": 0.6718937427632787,\n",
      "  \"runner_up_assignment\": [\n",
      "    \"class_2\",\n",
      "    \"class_1\"\n",
      "  ],\n",
      "  \"runner_up_correlation\": [\n",
      "    0.5817858149210493,\n",
      "    0.6141052482383532\n",
      "  ],\n",
      "  \"runner_up_probability\": [\n",
      "    0.11,\n",
      "    0.04\n",
      "  ],\n",
      "  \"aggregate_probability\": 0.85,\n",
      "  \"directly_assigned\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(json_results['results'][2]['class'], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49096069-4f99-43cb-8379-e50f8ca0d9a3",
   "metadata": {},
   "source": [
    "We see that the cell was assigned to `class_0`, that `0.85` of the random mapping iterations made that determination, and that the average correlation coefficient between the cell and the average gene expression profile for `class_0` in the space of marker genes was `0.672`. However, `0.11` of the random iterations chose `class_2` (average correlation coefficient `0.582`) and `0.04` of the iterations chose `class_1` (average correlation coefficient `0.614`). These latter figures can be taken as an indication of how trustworthy the mapping was.\n",
    "\n",
    "The `aggregate_probability` field is a running product of the `bootstrapping_probability` of cell at the given level in the taxonomy, i.e. because our taxonomy is structured `class -> subclass -> cluster`, the `aggregate_probability` at the subclass level is the product of the `bootstrapping_probability` at the subclass level with the `bootstrapping_probability` at the class level. The `aggregate_probability` at the cluster level is the product of `bootstrapping_probability` at all three levels in the taxonomy. A way to think about it is that the `bootstrapping_probability` at a given level is a conditional probability (conditioned on the assumption that the prior cell type assignments were correct). The `aggregate_probability` is the unconditional probability that the cell is a member of the given cell type.\n",
    "\n",
    "Finally `directly_assigned` is a boolean indicating whether or not the code actually mapped to that level in the taxonomy. The cell type mapper gives you the option to skip over levels of the taxonomy, in which case those levels are inferred from the assignments made at lower levels in the taxonomy. Let us explore what this means by using the `--flatten` command line argument, which tells the cell type mapper to skip all intermediate levels in the taxonomy and assign the cell directly to the leaf level (`cluster` in our taxonomy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34661957-366f-4699-96b8-a1eac3d441e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Running Hierarchical Mapping v1.4.1 with config ===\n",
      "{\n",
      "  \"obsm_clobber\": false,\n",
      "  \"type_assignment\": {\n",
      "    \"bootstrap_iteration\": 100,\n",
      "    \"n_processors\": 1,\n",
      "    \"n_runners_up\": 5,\n",
      "    \"bootstrap_factor\": 0.5,\n",
      "    \"rng_seed\": 661123,\n",
      "    \"bootstrap_factor_lookup\": null,\n",
      "    \"chunk_size\": 10000,\n",
      "    \"normalization\": \"raw\",\n",
      "    \"min_markers\": 10,\n",
      "    \"log_level\": \"ERROR\"\n",
      "  },\n",
      "  \"extended_result_path\": \"pipeline_example_data/flat_mapping_output.json\",\n",
      "  \"verbose_csv\": false,\n",
      "  \"map_to_ensembl\": false,\n",
      "  \"tmp_dir\": null,\n",
      "  \"query_path\": \"pipeline_example_data/unlabeled.h5ad\",\n",
      "  \"precomputed_stats\": {\n",
      "    \"path\": \"pipeline_example_data/precomputed_stats.h5\",\n",
      "    \"log_level\": \"ERROR\"\n",
      "  },\n",
      "  \"max_gb\": 100.0,\n",
      "  \"obsm_key\": null,\n",
      "  \"extended_result_dir\": null,\n",
      "  \"flatten\": true,\n",
      "  \"log_path\": null,\n",
      "  \"cloud_safe\": false,\n",
      "  \"csv_result_path\": \"pipeline_example_data/flat_mapping_output.csv\",\n",
      "  \"summary_metadata_path\": null,\n",
      "  \"log_level\": \"ERROR\",\n",
      "  \"nodes_to_drop\": null,\n",
      "  \"verbose_stdout\": true,\n",
      "  \"drop_level\": null,\n",
      "  \"hdf5_result_path\": null,\n",
      "  \"query_markers\": {\n",
      "    \"serialized_lookup\": \"pipeline_example_data/query_markers.json\",\n",
      "    \"log_level\": \"ERROR\"\n",
      "  }\n",
      "}\n",
      "ENV: is_torch_available: False\n",
      "ENV: is_cuda_available: False\n",
      "ENV: use_torch: False\n",
      "ENV: multiprocessing start method: spawn\n",
      "ENV: Python version: 3.10.15 (main, Oct  3 2024, 02:33:33) [Clang 14.0.6 ]\n",
      "ENV: anndata version: 0.11.1\n",
      "ENV: numpy version: 2.2.1\n",
      "BENCHMARK: spent 3.1519e-04 seconds validating config and copying data\n",
      "using ../precomputed_stats.h5 for precomputed_stats\n",
      "reading taxonomy_tree from ../precomputed_stats.h5\n",
      "/Users/scott.daniel/KnowledgeBase/knowledge_graph_prototypes/src/cell_type_mapper/taxonomy/utils.py:245: UserWarning: This taxonomy has no mapping from leaf_node -> rows in the cell by gene matrix\n",
      "  warnings.warn(\"This taxonomy has no mapping from leaf_node -> rows \"\n",
      "BENCHMARK: spent 5.7962e-03 seconds creating query marker cache\n",
      "Running CPU implementation of type assignment.\n",
      "8 of 8 cells in 1.30e+00 sec; predict 0.00e+00 sec of 1.30e+00 sec left\n",
      "BENCHMARK: spent 1.3212e+00 seconds assigning cell types\n",
      "Writing marker genes to output file\n",
      "MAPPING FROM SPECIFIED MARKERS RAN SUCCESSFULLY\n",
      "CLEANING UP\n"
     ]
    }
   ],
   "source": [
    "!python -m cell_type_mapper.cli.from_specified_markers \\\n",
    "--precomputed_stats.path pipeline_example_data/precomputed_stats.h5 \\\n",
    "--query_markers.serialized_lookup pipeline_example_data/query_markers.json \\\n",
    "--type_assignment.bootstrap_factor 0.5 \\\n",
    "--type_assignment.bootstrap_iteration 100 \\\n",
    "--type_assignment.rng_seed 661123 \\\n",
    "--type_assignment.n_processors 1 \\\n",
    "--type_assignment.normalization raw \\\n",
    "--query_path pipeline_example_data/unlabeled.h5ad \\\n",
    "--extended_result_path pipeline_example_data/flat_mapping_output.json \\\n",
    "--csv_result_path pipeline_example_data/flat_mapping_output.csv \\\n",
    "--flatten True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c57cfe4-8d61-41b4-a46c-b59ddad7c9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"cluster\": {\n",
      "    \"assignment\": \"cluster_010\",\n",
      "    \"bootstrapping_probability\": 0.71,\n",
      "    \"avg_correlation\": 0.6840062918673346,\n",
      "    \"runner_up_assignment\": [\n",
      "      \"cluster_000\",\n",
      "      \"cluster_200\",\n",
      "      \"cluster_110\"\n",
      "    ],\n",
      "    \"runner_up_correlation\": [\n",
      "      0.6822038267905279,\n",
      "      0.6303038659512773,\n",
      "      0.6143027060704218\n",
      "    ],\n",
      "    \"runner_up_probability\": [\n",
      "      0.16,\n",
      "      0.11,\n",
      "      0.02\n",
      "    ],\n",
      "    \"aggregate_probability\": 0.71,\n",
      "    \"directly_assigned\": true\n",
      "  },\n",
      "  \"cell_id\": \"cluster_010\",\n",
      "  \"subclass\": {\n",
      "    \"assignment\": \"subclass_01\",\n",
      "    \"bootstrapping_probability\": 0.71,\n",
      "    \"avg_correlation\": 0.6840062918673346,\n",
      "    \"aggregate_probability\": 0.71,\n",
      "    \"directly_assigned\": false\n",
      "  },\n",
      "  \"class\": {\n",
      "    \"assignment\": \"class_0\",\n",
      "    \"bootstrapping_probability\": 0.71,\n",
      "    \"avg_correlation\": 0.6840062918673346,\n",
      "    \"aggregate_probability\": 0.71,\n",
      "    \"directly_assigned\": false\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "with open('pipeline_example_data/flat_mapping_output.json', 'rb') as src:\n",
    "    flat_json_results = json.load(src)\n",
    "\n",
    "print(json.dumps(flat_json_results['results'][2], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8272f868-2eb1-4dc0-91d8-26cd43feea51",
   "metadata": {},
   "source": [
    "In the case of mapping with `--flatten True`, the mapper directly assigns the cell to the cluster level and infers the cell's subclass and class membership based on which subclasses and classes are ancestors of the assigned cluster. You can tell that this is what happened because `directly_assigned` is `false` in the class and subclass levels of the assignment. For book keeping purposes, `bootstrapping_probabiltiy`, `avg_correlation` and `aggregate_probability` for the class and subclass levels are copied directly from the cluster level, even though no bootstrapping iteration (or correlation with marker genes) was done at these levels.\n",
    "\n",
    "Let us look at one more cell in our original, hierarchical mapping example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d3bcb51-6e8d-4ec1-b40b-f3fb704d56b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"class\": {\n",
      "    \"assignment\": \"class_2\",\n",
      "    \"bootstrapping_probability\": 0.74,\n",
      "    \"avg_correlation\": 0.6806482010216238,\n",
      "    \"runner_up_assignment\": [\n",
      "      \"class_0\",\n",
      "      \"class_1\"\n",
      "    ],\n",
      "    \"runner_up_correlation\": [\n",
      "      0.6350877789185118,\n",
      "      0.6033932223539392\n",
      "    ],\n",
      "    \"runner_up_probability\": [\n",
      "      0.22,\n",
      "      0.04\n",
      "    ],\n",
      "    \"aggregate_probability\": 0.74,\n",
      "    \"directly_assigned\": true\n",
      "  },\n",
      "  \"subclass\": {\n",
      "    \"assignment\": \"subclass_20\",\n",
      "    \"bootstrapping_probability\": 1.0,\n",
      "    \"avg_correlation\": 0.6806482010216238,\n",
      "    \"runner_up_assignment\": [],\n",
      "    \"runner_up_correlation\": [],\n",
      "    \"runner_up_probability\": [],\n",
      "    \"aggregate_probability\": 0.74,\n",
      "    \"directly_assigned\": true\n",
      "  },\n",
      "  \"cluster\": {\n",
      "    \"assignment\": \"cluster_200\",\n",
      "    \"bootstrapping_probability\": 1.0,\n",
      "    \"avg_correlation\": 0.6806482010216238,\n",
      "    \"runner_up_assignment\": [],\n",
      "    \"runner_up_correlation\": [],\n",
      "    \"runner_up_probability\": [],\n",
      "    \"aggregate_probability\": 0.74,\n",
      "    \"directly_assigned\": true\n",
      "  },\n",
      "  \"cell_id\": \"cluster_200\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(json_results['results'][7], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0496b68-8c1d-45ad-8cd7-a4a17e9b147e",
   "metadata": {},
   "source": [
    "This cell was assigned to `class_2`. You will recall that only one subclass (`subclass_20`) and only one cluster (`cluster_200`) descend from `class_2`. In this case, though subclass and cluster were both directly assigned, the `bootstrapping_probability` at those levels is `1.0`. At the point where the cell was assigned to `class_2`, it **must** also belong to `subclass_20` and `cluster_200` according to our cell type taxonomy. No actual correlation was done. `bootstrapping_probability` was set to 1.0 and `avg_correlation` for the subclass and cluster were copied from the `avg_correlation` at the class level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2778a1ab-1999-4fef-9ff7-9e4144c1e3ea",
   "metadata": {},
   "source": [
    "# 6 -- Special case: small taxonomies\n",
    "\n",
    "We broke up the mapping and marker gene selection steps above because marker gene selection (especially reference marker selection) can be time consuming for large taxonomies. The code must compare all combinations of leaf nodes. For taxonomies with a few thousand nodes, this process can take hours. However, it only needs to be run once (in theory) for any given taxonomy, and the results can be resuded for different unlabeled datasets. For smaller taxonomies (taxonomies with a few hundred nodes) the marker gene selection process can be accomplished in minutes and there is no harm in re-running it for each unlabeled dataset (depending on your tolerance for \"wasting\" a few minutes). The advantage to this approach is that, if you end up mapping several datasets, each with a different set of measured genes in it, you can be certain that the marker genes will be selected with prior knowledge of the genes that are available in your unlabeled dataset and the code will not depend on the presence of a very good marker that is sadly unavailable in the unlabeled dataset.\n",
    "\n",
    "We have provided a command line tool for selecting the marker genes \"on the fly\" and mapping with those internally selected marker genes. Note that, for this tool, all of the parameters passed to the reference and query marker finder are passed to the single tool with the `query_markers` and `reference_markers` prefix as appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "692995c8-a393-4fcc-9c89-58587aa8ed7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to find reference markers\n",
      "writing /var/folders/6w/ny22h74j3sz8jdt_69ljc9srvkqr8_/T/tmp7f70b2t3/tmp7ze3m8ko/reference_markers.h5\n",
      "Starting precomputed_stats.h5\n",
      "8 of 28 taxon pairs in 1.41e+00 sec; predict 3.54e+00 sec of 4.95e+00 sec left\n",
      "16 of 28 taxon pairs in 2.75e+00 sec; predict 2.06e+00 sec of 4.82e+00 sec left\n",
      "24 of 28 taxon pairs in 3.95e+00 sec; predict 6.59e-01 sec of 4.61e+00 sec left\n",
      "32 of 28 taxon pairs in 5.14e+00 sec; predict -6.43e-01 sec of 4.50e+00 sec left\n",
      "Initial marker discovery took 5.16e+00 seconds\n",
      "Transposing markers took 1.04e-02 seconds\n",
      "Copying to /var/folders/6w/ny22h74j3sz8jdt_69ljc9srvkqr8_/T/tmp7f70b2t3/tmp7ze3m8ko/reference_markers.h5 took 1.39e-04 seconds\n",
      "Wrote reference_markers.h5\n",
      "REFERENCE MARKER FINDER RAN SUCCESSFULLY\n",
      "completed in 5.18e+00 seconds\n",
      "found reference markers\n",
      "found markers for 1 parents in 1.93e-02 minutes; predict 1.55e-01 of 1.74e-01 remaining\n",
      "found markers for 2 parents in 3.98e-02 minutes; predict 1.39e-01 of 1.79e-01 remaining\n",
      "found markers for 3 parents in 5.98e-02 minutes; predict 1.20e-01 of 1.79e-01 remaining\n",
      "found markers for 5 parents in 7.93e-02 minutes; predict 6.34e-02 of 1.43e-01 remaining\n",
      "found markers for 6 parents in 9.91e-02 minutes; predict 4.95e-02 of 1.49e-01 remaining\n",
      "found markers for 7 parents in 1.19e-01 minutes; predict 3.39e-02 of 1.52e-01 remaining\n",
      "QUERY MARKER FINDER RAN SUCCESSFULLY in 8.33e+00 seconds\n",
      "found query markers\n",
      "=== Running Hierarchical Mapping v1.4.1 with config ===\n",
      "{\n",
      "  \"summary_metadata_path\": null,\n",
      "  \"extended_result_path\": \"pipeline_example_data/otf_mapping_output.json\",\n",
      "  \"query_markers\": {\n",
      "    \"log_level\": \"ERROR\",\n",
      "    \"serialized_lookup\": \"/var/folders/6w/ny22h74j3sz8jdt_69ljc9srvkqr8_/T/tmp7f70b2t3/query_markers_s8zswnbl.json\"\n",
      "  },\n",
      "  \"obsm_key\": null,\n",
      "  \"obsm_clobber\": false,\n",
      "  \"type_assignment\": {\n",
      "    \"bootstrap_factor_lookup\": null,\n",
      "    \"chunk_size\": 10000,\n",
      "    \"n_processors\": 1,\n",
      "    \"bootstrap_factor\": 0.5,\n",
      "    \"normalization\": \"raw\",\n",
      "    \"min_markers\": 10,\n",
      "    \"n_runners_up\": 5,\n",
      "    \"rng_seed\": 661123,\n",
      "    \"bootstrap_iteration\": 100,\n",
      "    \"log_level\": \"ERROR\"\n",
      "  },\n",
      "  \"query_path\": \"pipeline_example_data/unlabeled.h5ad\",\n",
      "  \"tmp_dir\": \"/var/folders/6w/ny22h74j3sz8jdt_69ljc9srvkqr8_/T/tmp7f70b2t3\",\n",
      "  \"extended_result_dir\": null,\n",
      "  \"flatten\": false,\n",
      "  \"log_path\": null,\n",
      "  \"max_gb\": 100.0,\n",
      "  \"hdf5_result_path\": null,\n",
      "  \"map_to_ensembl\": false,\n",
      "  \"nodes_to_drop\": null,\n",
      "  \"log_level\": \"ERROR\",\n",
      "  \"csv_result_path\": \"pipeline_example_data/otf_mapping_output.csv\",\n",
      "  \"cloud_safe\": false,\n",
      "  \"drop_level\": null,\n",
      "  \"verbose_stdout\": true,\n",
      "  \"precomputed_stats\": {\n",
      "    \"path\": \"pipeline_example_data/precomputed_stats.h5\",\n",
      "    \"log_level\": \"ERROR\"\n",
      "  },\n",
      "  \"verbose_csv\": false\n",
      "}\n",
      "ENV: is_torch_available: False\n",
      "ENV: is_cuda_available: False\n",
      "ENV: use_torch: False\n",
      "ENV: multiprocessing start method: spawn\n",
      "ENV: Python version: 3.10.15 (main, Oct  3 2024, 02:33:33) [Clang 14.0.6 ]\n",
      "ENV: anndata version: 0.11.1\n",
      "ENV: numpy version: 2.2.1\n",
      "FILE TRACKER: copied ../unlabeled.h5ad to ../unlabeled_34ksjs2h.h5ad\n",
      "FILE TRACKER: copied ../precomputed_stats.h5 to ../precomputed_stats_msxip5jy.h5\n",
      "BENCHMARK: spent 2.6431e-03 seconds validating config and copying data\n",
      "using ../precomputed_stats_msxip5jy.h5 for precomputed_stats\n",
      "reading taxonomy_tree from ../precomputed_stats_msxip5jy.h5\n",
      "/Users/scott.daniel/KnowledgeBase/knowledge_graph_prototypes/src/cell_type_mapper/taxonomy/utils.py:245: UserWarning: This taxonomy has no mapping from leaf_node -> rows in the cell by gene matrix\n",
      "  warnings.warn(\"This taxonomy has no mapping from leaf_node -> rows \"\n",
      "BENCHMARK: spent 8.1160e-03 seconds creating query marker cache\n",
      "Running CPU implementation of type assignment.\n",
      "8 of 8 cells in 1.24e+00 sec; predict 0.00e+00 sec of 1.24e+00 sec left\n",
      "BENCHMARK: spent 1.2566e+00 seconds assigning cell types\n",
      "Writing marker genes to output file\n",
      "FILE TRACKER: cleaning up ../file_tracker_1ff6xzz3\n",
      "MAPPING FROM SPECIFIED MARKERS RAN SUCCESSFULLY\n",
      "CLEANING UP\n",
      "MAPPING FROM ON-THE-FLY MARKERS RAN SUCCESSFULLY\n"
     ]
    }
   ],
   "source": [
    "!python -m cell_type_mapper.cli.map_to_on_the_fly_markers \\\n",
    "--precomputed_stats.path pipeline_example_data/precomputed_stats.h5 \\\n",
    "--type_assignment.bootstrap_factor 0.5 \\\n",
    "--type_assignment.bootstrap_iteration 100 \\\n",
    "--type_assignment.rng_seed 661123 \\\n",
    "--type_assignment.normalization raw \\\n",
    "--query_path pipeline_example_data/unlabeled.h5ad \\\n",
    "--extended_result_path pipeline_example_data/otf_mapping_output.json \\\n",
    "--csv_result_path pipeline_example_data/otf_mapping_output.csv \\\n",
    "--query_markers.n_per_utility 10 \\\n",
    "--reference_markers.n_valid 20 \\\n",
    "--n_processors 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0eda614-590c-482e-93b3-5c725f0a761e",
   "metadata": {},
   "source": [
    "Let's load the results of our \"on the fly marker mapping\" and show that they are identical to the results we got when we split up marker selection and mapping into different steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c3e1093-8b57-4c93-8144-1784fd2fb922",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pipeline_example_data/otf_mapping_output.json', 'rb') as src:\n",
    "    otf_json_results = json.load(src)\n",
    "\n",
    "\n",
    "assert otf_json_results['results'] == json_results['results']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3f4854-165f-45cc-ad1d-db25b7b6fd2a",
   "metadata": {},
   "source": [
    "Here is how to call the same on-the-fly mapping programmatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0e92400e-e682-4f01-8eef-b841edbddd92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to find reference markers\n",
      "writing /var/folders/6w/ny22h74j3sz8jdt_69ljc9srvkqr8_/T/tmp32i931cw/tmpx83oiwca/reference_markers.h5\n",
      "Starting precomputed_stats.h5\n",
      "8 of 28 taxon pairs in 6.22e-01 sec; predict 1.56e+00 sec of 2.18e+00 sec left\n",
      "16 of 28 taxon pairs in 1.24e+00 sec; predict 9.30e-01 sec of 2.17e+00 sec left\n",
      "24 of 28 taxon pairs in 1.88e+00 sec; predict 3.13e-01 sec of 2.19e+00 sec left\n",
      "32 of 28 taxon pairs in 2.48e+00 sec; predict -3.10e-01 sec of 2.17e+00 sec left\n",
      "Initial marker discovery took 2.50e+00 seconds\n",
      "Transposing markers took 9.84e-03 seconds\n",
      "Copying to /var/folders/6w/ny22h74j3sz8jdt_69ljc9srvkqr8_/T/tmp32i931cw/tmpx83oiwca/reference_markers.h5 took 1.38e-04 seconds\n",
      "Wrote reference_markers.h5\n",
      "REFERENCE MARKER FINDER RAN SUCCESSFULLY\n",
      "completed in 2.52e+00 seconds\n",
      "found reference markers\n",
      "found markers for 1 parents in 9.84e-03 minutes; predict 7.88e-02 of 8.86e-02 remaining\n",
      "found markers for 2 parents in 2.01e-02 minutes; predict 7.03e-02 of 9.04e-02 remaining\n",
      "found markers for 3 parents in 3.00e-02 minutes; predict 6.00e-02 of 9.00e-02 remaining\n",
      "found markers for 5 parents in 4.00e-02 minutes; predict 3.20e-02 of 7.20e-02 remaining\n",
      "found markers for 6 parents in 4.99e-02 minutes; predict 2.50e-02 of 7.49e-02 remaining\n",
      "found markers for 7 parents in 5.98e-02 minutes; predict 1.71e-02 of 7.69e-02 remaining\n",
      "QUERY MARKER FINDER RAN SUCCESSFULLY in 3.68e+00 seconds\n",
      "found query markers\n",
      "=== Running Hierarchical Mapping v1.4.1 with config ===\n",
      "{\n",
      "  \"obsm_key\": null,\n",
      "  \"verbose_stdout\": true,\n",
      "  \"type_assignment\": {\n",
      "    \"min_markers\": 10,\n",
      "    \"n_processors\": 1,\n",
      "    \"n_runners_up\": 5,\n",
      "    \"chunk_size\": 10000,\n",
      "    \"bootstrap_iteration\": 100,\n",
      "    \"log_level\": \"ERROR\",\n",
      "    \"bootstrap_factor_lookup\": null,\n",
      "    \"bootstrap_factor\": 0.5,\n",
      "    \"rng_seed\": 661123,\n",
      "    \"normalization\": \"raw\"\n",
      "  },\n",
      "  \"query_path\": \"pipeline_example_data/unlabeled.h5ad\",\n",
      "  \"tmp_dir\": \"/var/folders/6w/ny22h74j3sz8jdt_69ljc9srvkqr8_/T/tmp32i931cw\",\n",
      "  \"extended_result_dir\": null,\n",
      "  \"log_level\": \"ERROR\",\n",
      "  \"precomputed_stats\": {\n",
      "    \"path\": \"pipeline_example_data/precomputed_stats.h5\",\n",
      "    \"log_level\": \"ERROR\"\n",
      "  },\n",
      "  \"verbose_csv\": false,\n",
      "  \"query_markers\": {\n",
      "    \"serialized_lookup\": \"/var/folders/6w/ny22h74j3sz8jdt_69ljc9srvkqr8_/T/tmp32i931cw/query_markers_0_q0vlwc.json\",\n",
      "    \"log_level\": \"ERROR\"\n",
      "  },\n",
      "  \"drop_level\": null,\n",
      "  \"summary_metadata_path\": null,\n",
      "  \"max_gb\": 100.0,\n",
      "  \"flatten\": false,\n",
      "  \"cloud_safe\": false,\n",
      "  \"log_path\": null,\n",
      "  \"map_to_ensembl\": false,\n",
      "  \"csv_result_path\": \"pipeline_example_data/otf_mapping_output.csv\",\n",
      "  \"obsm_clobber\": false,\n",
      "  \"hdf5_result_path\": null,\n",
      "  \"extended_result_path\": \"pipeline_example_data/otf_mapping_output.json\",\n",
      "  \"nodes_to_drop\": null\n",
      "}\n",
      "ENV: is_torch_available: False\n",
      "ENV: is_cuda_available: False\n",
      "ENV: use_torch: False\n",
      "ENV: multiprocessing start method: spawn\n",
      "ENV: Python version: 3.10.15 (main, Oct  3 2024, 02:33:33) [Clang 14.0.6 ]\n",
      "ENV: anndata version: 0.11.1\n",
      "ENV: numpy version: 2.2.1\n",
      "FILE TRACKER: copied ../unlabeled.h5ad to ../unlabeled_4dtonz7c.h5ad\n",
      "FILE TRACKER: copied ../precomputed_stats.h5 to ../precomputed_stats__rb3we5w.h5\n",
      "BENCHMARK: spent 2.4879e-03 seconds validating config and copying data\n",
      "using ../precomputed_stats__rb3we5w.h5 for precomputed_stats\n",
      "reading taxonomy_tree from ../precomputed_stats__rb3we5w.h5\n",
      "BENCHMARK: spent 8.1038e-03 seconds creating query marker cache\n",
      "Running CPU implementation of type assignment.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/scott.daniel/KnowledgeBase/knowledge_graph_prototypes/src/cell_type_mapper/taxonomy/utils.py:245: UserWarning: This taxonomy has no mapping from leaf_node -> rows in the cell by gene matrix\n",
      "  warnings.warn(\"This taxonomy has no mapping from leaf_node -> rows \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 of 8 cells in 6.50e-01 sec; predict 0.00e+00 sec of 6.50e-01 sec left\n",
      "BENCHMARK: spent 6.6741e-01 seconds assigning cell types\n",
      "Writing marker genes to output file\n",
      "FILE TRACKER: cleaning up ../file_tracker__rqeul0p\n",
      "MAPPING FROM SPECIFIED MARKERS RAN SUCCESSFULLY\n",
      "CLEANING UP\n",
      "MAPPING FROM ON-THE-FLY MARKERS RAN SUCCESSFULLY\n"
     ]
    }
   ],
   "source": [
    "from cell_type_mapper.cli.map_to_on_the_fly_markers import (\n",
    "    OnTheFlyMapper\n",
    ")\n",
    "\n",
    "\n",
    "config = {\n",
    "    'precomputed_stats': {\n",
    "        'path': 'pipeline_example_data/precomputed_stats.h5'\n",
    "    },\n",
    "    'type_assignment': {\n",
    "        'bootstrap_factor': 0.5,\n",
    "        'bootstrap_iteration': 100,\n",
    "        'rng_seed': 661123,\n",
    "        'normalization': 'raw'\n",
    "    },\n",
    "    'reference_markers': {'n_valid': 20},\n",
    "    'query_markers': {'n_per_utility': 10},\n",
    "    'query_path': 'pipeline_example_data/unlabeled.h5ad',\n",
    "    'extended_result_path': 'pipeline_example_data/otf_mapping_output.json',\n",
    "    'csv_result_path': 'pipeline_example_data/otf_mapping_output.csv',\n",
    "    'n_processors': 1\n",
    "}\n",
    "\n",
    "\n",
    "runner = OnTheFlyMapper(args=[], input_data=config)\n",
    "runner.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f409dd37-a4e0-4894-b96d-8cce2cb2bc1f",
   "metadata": {},
   "source": [
    "One potential disadvantage to this approach is that there is less of a \"paper trail.\" The reference marker and query marker files are not written out to disk. Only the final mappings are written to disk. However, you can find the marker gene lookup table that was actually used to map your data in the JSON results file here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b34373fb-a7c1-4268-b4d7-6715094cd833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class/class_0': ['g30',\n",
       "  'g32',\n",
       "  'g41',\n",
       "  'g42',\n",
       "  'g45',\n",
       "  'g57',\n",
       "  'g58',\n",
       "  'g59',\n",
       "  'g60',\n",
       "  'g61',\n",
       "  'g62',\n",
       "  'g63',\n",
       "  'g64',\n",
       "  'g68',\n",
       "  'g70',\n",
       "  'g75',\n",
       "  'g76',\n",
       "  'g77',\n",
       "  'g78',\n",
       "  'g79',\n",
       "  'g80',\n",
       "  'g81',\n",
       "  'g82',\n",
       "  'g83',\n",
       "  'g84',\n",
       "  'g85',\n",
       "  'g86',\n",
       "  'g87',\n",
       "  'g88',\n",
       "  'g89'],\n",
       " 'class/class_1': ['g30',\n",
       "  'g31',\n",
       "  'g32',\n",
       "  'g33',\n",
       "  'g34',\n",
       "  'g35',\n",
       "  'g59',\n",
       "  'g60',\n",
       "  'g62',\n",
       "  'g65',\n",
       "  'g68',\n",
       "  'g75',\n",
       "  'g77',\n",
       "  'g78',\n",
       "  'g79',\n",
       "  'g80',\n",
       "  'g81',\n",
       "  'g82',\n",
       "  'g83',\n",
       "  'g84',\n",
       "  'g85',\n",
       "  'g86',\n",
       "  'g87',\n",
       "  'g88',\n",
       "  'g89'],\n",
       " 'class/class_2': [],\n",
       " 'subclass/subclass_00': ['g61',\n",
       "  'g64',\n",
       "  'g65',\n",
       "  'g70',\n",
       "  'g73',\n",
       "  'g75',\n",
       "  'g76',\n",
       "  'g77',\n",
       "  'g78',\n",
       "  'g79',\n",
       "  'g80',\n",
       "  'g81',\n",
       "  'g82',\n",
       "  'g83',\n",
       "  'g84',\n",
       "  'g85',\n",
       "  'g86',\n",
       "  'g87',\n",
       "  'g88',\n",
       "  'g89'],\n",
       " 'subclass/subclass_01': ['g60',\n",
       "  'g61',\n",
       "  'g62',\n",
       "  'g64',\n",
       "  'g66',\n",
       "  'g70',\n",
       "  'g75',\n",
       "  'g76',\n",
       "  'g77',\n",
       "  'g78',\n",
       "  'g79',\n",
       "  'g80',\n",
       "  'g81',\n",
       "  'g82',\n",
       "  'g83',\n",
       "  'g85',\n",
       "  'g86',\n",
       "  'g87',\n",
       "  'g88',\n",
       "  'g89'],\n",
       " 'subclass/subclass_10': ['g60',\n",
       "  'g61',\n",
       "  'g62',\n",
       "  'g64',\n",
       "  'g68',\n",
       "  'g69',\n",
       "  'g75',\n",
       "  'g77',\n",
       "  'g78',\n",
       "  'g79',\n",
       "  'g80',\n",
       "  'g81',\n",
       "  'g82',\n",
       "  'g83',\n",
       "  'g84',\n",
       "  'g85',\n",
       "  'g86',\n",
       "  'g87',\n",
       "  'g88',\n",
       "  'g89'],\n",
       " 'subclass/subclass_11': [],\n",
       " 'subclass/subclass_20': [],\n",
       " 'None': ['g1',\n",
       "  'g2',\n",
       "  'g3',\n",
       "  'g4',\n",
       "  'g5',\n",
       "  'g6',\n",
       "  'g7',\n",
       "  'g8',\n",
       "  'g9',\n",
       "  'g20',\n",
       "  'g21',\n",
       "  'g22',\n",
       "  'g23',\n",
       "  'g24',\n",
       "  'g25',\n",
       "  'g26',\n",
       "  'g27',\n",
       "  'g28',\n",
       "  'g29',\n",
       "  'g30',\n",
       "  'g31',\n",
       "  'g32',\n",
       "  'g33',\n",
       "  'g34',\n",
       "  'g35',\n",
       "  'g41',\n",
       "  'g42',\n",
       "  'g45',\n",
       "  'g57',\n",
       "  'g58',\n",
       "  'g59',\n",
       "  'g60',\n",
       "  'g61',\n",
       "  'g62',\n",
       "  'g63',\n",
       "  'g64',\n",
       "  'g68',\n",
       "  'g70',\n",
       "  'g75',\n",
       "  'g76',\n",
       "  'g77',\n",
       "  'g78',\n",
       "  'g79',\n",
       "  'g80',\n",
       "  'g81',\n",
       "  'g82',\n",
       "  'g83',\n",
       "  'g84',\n",
       "  'g85',\n",
       "  'g86',\n",
       "  'g87',\n",
       "  'g88',\n",
       "  'g89']}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "otf_json_results['marker_genes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5273d09d-dfb0-4e77-87ae-a12824396bda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
